{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#load csv to dataframe\n",
    "#URL\n",
    "url = 'https://raw.githubusercontent.com/dipalira/Melbourne-Housing-Data-Kaggle/master/Data/Melbourne_housing_FULL.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 \n",
    "df['Price'] = df['Price'].dropna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows = df['Price'].isnull().sum()\n",
    "null_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_null = (null_rows / 34857) * 100\n",
    "print(\"null rows %: \", percent_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\n",
    "# Frequency of each property type\n",
    "prop_counts = df['Type'].value_counts()\n",
    "\n",
    "# Most common property type\n",
    "most_common_type = prop_counts.idxmax()\n",
    "\n",
    "# Percentage of the most common property type\n",
    "percentage_most_common = (prop_counts.max() / len(df)) * 100\n",
    "\n",
    "print(f\"The most common property type is {most_common_type}, representing {percentage_most_common:.2f}% of properties.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 3. Plot the frequencies of property types in descending order\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mbarplot(x\u001b[38;5;241m=\u001b[39mprop_counts\u001b[38;5;241m.\u001b[39mindex, y\u001b[38;5;241m=\u001b[39mprop_counts\u001b[38;5;241m.\u001b[39mvalues, order\u001b[38;5;241m=\u001b[39mprop_counts\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrequency of Each Property Type in Descending Order\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "# 3. Plot the frequencies of property types in descending order\n",
    "sns.barplot(x=prop_counts.index, y=prop_counts.values, order=prop_counts.index)\n",
    "plt.title('Frequency of Each Property Type in Descending Order')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "# Group by number of rooms and calculate the median price\n",
    "median_price_by_rooms = df.groupby('Rooms')['Price'].median().reset_index()\n",
    "\n",
    "# Create a bar chart\n",
    "sns.barplot(x='Rooms', y='Price', data=median_price_by_rooms)\n",
    "plt.title('Median Property Price by Number of Rooms')\n",
    "plt.ylabel('Median Price')\n",
    "plt.xlabel('Number of Rooms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Relationship between property price and number of rooms (Spearman)\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Calculate Spearman correlation\n",
    "corr_spearman, _ = spearmanr(df['Price'], df['Rooms'])\n",
    "\n",
    "print(f\"Spearman correlation between Price and Rooms: {corr_spearman:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spearman correlation output: nan \n",
    "#Spearman correlation coefficient cannot handle NaN values.\n",
    "\n",
    "# Drop rows with null values in Price and Rooms\n",
    "data_cleaned = df[['Price', 'Rooms']].dropna()\n",
    "\n",
    "# Calculate Spearman correlation after handling null values\n",
    "corr_spearman, _ = spearmanr(data_cleaned['Price'], data_cleaned['Rooms'])\n",
    "\n",
    "print(f\"Spearman correlation between Price and Rooms (after cleaning): {corr_spearman:.2f}\")\n",
    "\n",
    "#Moderate to strong correlation: Spearman correlation between 0.3 and 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 Relationship between CBD distance and price \n",
    "# Scatter plot of Price vs CBD distance\n",
    "\n",
    "# Show all columns in DF as list (to find Col. about CBD)\n",
    "print(list(df.columns))\n",
    "\n",
    "sns.scatterplot(x='Distance', y='Price', data=df)\n",
    "plt.title('Scatter Plot of Property Price vs Distance from CBD')\n",
    "plt.ylabel('Price')\n",
    "plt.xlabel('Distance from CBD')\n",
    "plt.show()\n",
    "\n",
    "# Calculate Spearman correlation between Price and CBD distance\n",
    "corr_cbd, _ = spearmanr(df['Price'], df['Distance'])\n",
    "\n",
    "print(f\"Spearman correlation between Price and CBD distance: {corr_cbd:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price       7610\n",
      "Distance       1\n",
      "dtype: int64\n",
      "Spearman correlation between Price and CBD distance (after cleaning): -0.19\n"
     ]
    }
   ],
   "source": [
    "#(6. continued) Output Spearman correlation between Price and CBD distance: nan\n",
    "print(df[['Price', 'Distance']].isnull().sum())\n",
    "\n",
    "# Remove null values for Price y Distance\n",
    "data_cleaned = df[['Price', 'Distance']].dropna()\n",
    "\n",
    "# Calc correl after cleaning data\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "corr_spearman, _ = spearmanr(data_cleaned['Price'], data_cleaned['Distance'])\n",
    "\n",
    "print(f\"Spearman correlation between Price and CBD distance (after cleaning): {corr_spearman:.2f}\")\n",
    "#Output : -0.19.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#after cleaning one by one in several Qs\n",
    "df_clean = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. \n",
    "# Scatter plot of Property Size vs Property Price\n",
    "sns.scatterplot(x='Landsize', y='Price', data=df_clean)\n",
    "plt.title('Scatter Plot of Property Size vs Price')\n",
    "plt.ylabel('Price')\n",
    "plt.xlabel('Property Size')\n",
    "plt.show()\n",
    "\n",
    "# Calculate Spearman correlation between Property Size and Price\n",
    "corr_size, _ = spearmanr(df_clean['Price'], df_clean['Landsize'])\n",
    "\n",
    "print(f\"Spearman correlation between Property Size and Price: {corr_size:.2f}\")\n",
    "# Weak positive correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.Using quantile-based discretization\n",
    "# Categorize land size into 7 quantiles\n",
    "df_clean['Size_Category'] = pd.qcut(df_clean['Landsize'], q=7)\n",
    "\n",
    "# Calculate median price for each land size category\n",
    "median_price_by_size = df_clean.groupby('Size_Category')['Price'].median().reset_index()\n",
    "\n",
    "# Create a bar plot for median price by land size \n",
    "sns.barplot(x='Size_Category', y='Price', data=median_price_by_size)\n",
    "plt.title('Median Price by Landsize (Quantiles)')\n",
    "plt.ylabel('Median Price')\n",
    "plt.xlabel('Landsize Category')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Detecting Outliers with Tukey's Method and Box Plot\n",
    "# Create a box plot for property prices to detect outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['Price'])  \n",
    "plt.title('Boxplot of Property Prices')\n",
    "plt.show()\n",
    "\n",
    "# Use Tukey's method to remove outliers\n",
    "Q1 = df['Price'].quantile(0.25)\n",
    "Q3 = df['Price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(9 Cont)\n",
    "\n",
    "# Create a new DataFrame without outliers\n",
    "df_no_outliers = df[(df['Price'] >= lower_bound) & (df['Price'] <= upper_bound)]\n",
    "\n",
    "# Calculate the percentage of outliers\n",
    "outliers_count = len(df) - len(df_no_outliers)\n",
    "outliers_percentage = (outliers_count / len(df)) * 100\n",
    "print(f'Percentage of properties identified as outliers: {outliers_percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = df['Price'].quantile(0.25)\n",
    "Q3 = df['Price'].quantile(0.75)\n",
    "\n",
    "# Calculate the IQR (Interquartile Range)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the upper and lower bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f'Q1 (25th percentile): {Q1}')\n",
    "print(f'Q3 (75th percentile): {Q3}')\n",
    "print(f'IQR (Interquartile Range): {IQR}')\n",
    "print(f'Lower bound for outliers: {lower_bound}')\n",
    "print(f'Upper bound for outliers: {upper_bound}')\n",
    "\n",
    "# Filter out the outliers\n",
    "df_no_outliers = df[(df['Price'] >= lower_bound) & (df['Price'] <= upper_bound)]\n",
    "\n",
    "# Calculate the percentage of outliers\n",
    "outliers_count = len(df) - len(df_no_outliers)\n",
    "outliers_percentage = (outliers_count / len(df)) * 100\n",
    "print(f'Percentage of properties identified as outliers: {outliers_percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 Price Distribution, QQ Plot, Skewness, and Kurtosis\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import skew, kurtosis\n",
    "# Create a QQ plot to compare the price distribution to a normal distribution\n",
    "sm.qqplot(df_clean['Price'], line ='45')\n",
    "plt.title('QQ Plot of Property Prices')\n",
    "plt.show()\n",
    "\n",
    "# Calculate skewness and kurtosis\n",
    "price_skewness = skew(df_clean['Price'])\n",
    "price_kurtosis = kurtosis(df_clean['Price'], fisher=False)\n",
    "print(f'Skewness: {price_skewness:.2f}')\n",
    "print(f'Kurtosis: {price_kurtosis:.2f}')\n",
    "\n",
    "#positive Skew\n",
    "#leptokurtic distribution (heavy tails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11 Kolmogorov-Smirnov test\n",
    "# Perform the Kolmogorov-Smirnov test on the price distribution\n",
    "from scipy.stats import kstest\n",
    "\n",
    "ks_statistic, p_value = kstest(df['Price'], 'norm', args=(df['Price'].mean(), df['Price'].std()))\n",
    "print(f'KS Statistic: {ks_statistic:.4f}, p-value: {p_value:.4f}')\n",
    "\n",
    "# If p-value < 0.05, we reject the null hypothesis that the distribution is normal\n",
    "if p_value < 0.05:\n",
    "    print(\"The distribution of property prices is not normal.\")\n",
    "else:\n",
    "    print(\"The distribution of property prices is normal.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12 \n",
    "# Create a box plot for property prices grouped by property type\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Type', y='Price', data=df)  \n",
    "plt.title('Distribution of Property Prices by Property Type')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "# Group by Region and calculate the median price\n",
    "region_median_prices = df.groupby('Regionname')['Price'].median()\n",
    "\n",
    "# Find the region with the highest and lowest median prices\n",
    "highest_median_region = region_median_prices.idxmax()\n",
    "lowest_median_region = region_median_prices.idxmin()\n",
    "\n",
    "print(f'Region with the highest median price: {highest_median_region}')\n",
    "print(f'Region with the lowest median price: {lowest_median_region}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14 Chi-square test for independence between Region and Price\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame with 'Regionname' and 'Price' columns\n",
    "\n",
    "# Discretize prices into categories\n",
    "df['PriceCategory'] = pd.qcut(df['Price'], q=4, labels=['Low', 'Medium-Low', 'Medium-High', 'High'])\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df['Regionname'], df['PriceCategory'])\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2_stat, p_val, dof, ex = chi2_contingency(contingency_table)\n",
    "\n",
    "# Calculate Cramer's V\n",
    "def cramers_v(chi2, n, min_dim):\n",
    "    return np.sqrt((chi2/n) / (min_dim-1))\n",
    "\n",
    "n = contingency_table.sum().sum()\n",
    "min_dim = min(contingency_table.shape) - 1\n",
    "cramers_v_value = cramers_v(chi2_stat, n, min_dim)\n",
    "\n",
    "# Print results\n",
    "print(f'Chi-square statistic: {chi2_stat:.2f}')\n",
    "print(f'p-value: {p_val:.4f}')\n",
    "print(f'Degrees of freedom: {dof}')\n",
    "print(f\"Cramer's V: {cramers_v_value:.4f}\")\n",
    "\n",
    "# Display the contingency table\n",
    "print(\"\\nContingency Table:\")\n",
    "print(contingency_table)\n",
    "\n",
    "# Optional: Visualize the contingency table\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(contingency_table, annot=True, cmap='YlGnBu', fmt='d')\n",
    "plt.title('Contingency Table: Region vs Price Category')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "# Convert 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Find the earliest and latest year\n",
    "earliest_year = df['Date'].dt.year.min()\n",
    "latest_year = df['Date'].dt.year.max()\n",
    "\n",
    "# Calculate the median prices for the earliest and latest year\n",
    "median_price_earliest = df[df['Date'].dt.year == earliest_year]['Price'].median()\n",
    "median_price_latest = df[df['Date'].dt.year == latest_year]['Price'].median()\n",
    "\n",
    "# Calculate percentage change\n",
    "percent_change = ((median_price_latest - median_price_earliest) / median_price_earliest) * 100\n",
    "print(f'Percentage change in median price: {percent_change:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16\n",
    "# Extract month from the 'Date' column\n",
    "# Convert 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "# Now you can use the .dt accessor to extract the year or month, for example:\n",
    "df['Year'] = df['Date'].dt.year \n",
    "df['Month'] = df['Date'].dt.month  \n",
    "\n",
    "# Find the month with the most sales\n",
    "month_with_most_sales = df['Month'].value_counts().idxmax()\n",
    "print(f'Month with the most property sales: {month_with_most_sales}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
